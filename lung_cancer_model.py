# -*- coding: utf-8 -*-
"""Lung_Cancer_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qu98cSLKcSgc6KZAl6uc0GJwZyjTJqSq

# **LUNG CANCER PREDICTION MODEL**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, accuracy_score

data = pd.read_csv('/content/survey lung cancer.csv')
data.head()

"""# **EDA**"""

data.info()

# plotting graph for output classes counts

plt.figure(figsize=(7,8))
sns.countplot(x = 'LUNG_CANCER',data = data)

# plotting graph for output classes counts

plt.figure(figsize=(7,8))
sns.countplot(x = 'GENDER',data = data)

from sklearn.preprocessing import LabelEncoder
lb = LabelEncoder()
data['GENDER']= lb.fit_transform(data['GENDER'])
data['LUNG_CANCER']= lb.fit_transform(data['LUNG_CANCER'])

data.head()

# plotting variation graphs for each property

data.hist(figsize = (25,15))

# Plotting the correlation heatmap
corrmat = data.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(25,15))

g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap="RdYlGn")

X = data.iloc[:,:-1]
y = data.iloc[:,-1]

X.head()

y.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

X_train.head()

X_test.head()

"""# RandomForest Classifier"""

from sklearn.ensemble import RandomForestClassifier
rf_classifier = RandomForestClassifier()
rf_classifier = rf_classifier.fit(X_train, y_train)

# Prediction
y_pred = rf_classifier.predict(X_test)

# Making the Confusion Matrix

cm = confusion_matrix(y_test, y_pred)
print(classification_report(y_test, y_pred))

# Get feature importances from the trained random forest classifier
importance_scores = rf_classifier.feature_importances_

# Sort the feature importances and corresponding feature names in descending order
sorted_indices = np.argsort(importance_scores)[::-1]
sorted_scores = importance_scores[sorted_indices]
sorted_features = X_train.columns[sorted_indices]  # Assuming you have named columns in your dataset

# Visualize the feature importances
plt.bar(range(len(sorted_scores)), sorted_scores)
plt.xticks(range(len(sorted_scores)), sorted_features, rotation='vertical')
plt.xlabel('Features')
plt.ylabel('Importance Scores')
plt.show()

